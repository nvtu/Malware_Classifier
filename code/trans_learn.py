from resnet import *
import os
import os.path as osp
import cv2
from torch.autograd import Variable as V
from torchvision import transforms as trn
from PIL import Image
import multiprocessing
from multiprocessing import Process
from utils import *
import numpy as np


def returnTF():
    # load the image transformer
    tf = trn.Compose([
        trn.Resize((224,224)),
        trn.ToTensor(),
        trn.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    return tf


def group_async_task(params, model):
    feature_blobs = []
    def hook_feature(module, input, output):
        feature_blobs.append(np.squeeze(output.data.cpu().numpy()))

    feature_names = ['layer4', 'avgpool']
    for name in feature_names:
        model._modules.get(name).register_forward_hook(hook_feature)
    for p in params:
        extract_resnet_feat(*p, model, feature_blobs)
        feature_blobs = []


def extract_resnet_feat(image_path, tf, output_path, model, feature_blobs):
    output_filepath = osp.join(output_path, osp.splitext(image_path.split('/')[-1])[0] + '.npy')
    print(output_filepath)
    if osp.exists(output_filepath):
        return
    image = Image.open(image_path) 
    image = image.convert('RGB')
    input_img = V(tf(image).unsqueeze(0))
    logit = model.forward(input_img)
    # Get features from average pooling layer
    np.save(output_filepath, feature_blobs[1])


def run_multiprocess_extract(model, img_paths):
    num_processes = max(1, multiprocessing.cpu_count() - 1)
    ntask_per_process = img_paths.__len__() // num_processes + 1
    p = []
    for i in range(num_processes):
        sub_p = img_paths[i * ntask_per_process : min(i * ntask_per_process + ntask_per_process, img_paths.__len__())]
        p.append(Process(target=group_async_task, args=(sub_p, model)))
        p[-1].start()
    for _p in p:
        _p.join()


def load_train_params(image_path, output_path):
    tf = returnTF()
    params = []
    for root, dirs, files in os.walk(image_path):
        for f in files:
            _f = osp.join(root, f)
            label = root.split('/')[-1]
            _out = osp.join(output_path, label)
            params.append((_f, tf, _out))
    return params


def create_train_output_path(image_path, output_path):
    create_folder(output_path)
    for root, dirs, files in os.walk(image_path):
        for d in dirs:
            _d = osp.join(output_path, d)
            create_folder(_d)


def load_test_params(image_path, output_path):
    tf = returnTF()
    params = []
    for f in sorted(os.listdir(image_path)):
        _f = osp.join(image_path, f)
        params.append((_f, tf, output_path))
    return params


def create_test_output_path(output_path):
    create_folder(output_path)


if __name__ == '__main__':
    model = resnet50(pretrained=True)
    model.eval()

    image_path = osp.join(os.getcwd(), '..', 'train', 'data', 'image')
    output_path = osp.join(os.getcwd(), '..', 'train', 'data', 'resnet50')
    create_train_output_path(image_path, output_path)
    params = load_train_params(image_path, output_path)
    run_multiprocess_extract(model, params)

    image_path = osp.join(os.getcwd(), '..', 'test', 'data', 'image')
    output_path = osp.join(os.getcwd(), '..', 'test', 'data', 'resnet50')
    params = load_test_params(image_path, output_path)
    create_test_output_path(output_path)
    run_multiprocess_extract(model, params)
